{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background: linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F); /* Gradient Background */\n",
    "          font-family: 'Roboto', sans-serif;\n",
    "          color: #F39C12; /* White Text for Contrast */\n",
    "          font-size: 1.9rem;\n",
    "          text-align: center;\n",
    "          padding: 20px 35px;\n",
    "          border-radius: 40px;\n",
    "          box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "          letter-spacing: 1px;\">\n",
    "    SMS CLASSIFIER : SPAM OR HAM\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img.jpg\" alt=\"image\" style=\"width: 500px;\"/>\n",
    "</p>\n",
    "\n",
    "   <a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:150%;text-align:center;border-radius:20px 60px;\">TABLE OF CONTENTS</p>   \n",
    "    \n",
    "* [1. Dataset](#1)\n",
    "    \n",
    "* [2. Importing Libraries](#2)\n",
    "    \n",
    "* [3. Loading Data](#3)\n",
    "    \n",
    "* [4. Visualization](#4)\n",
    "     \n",
    "* [5. Text Preprocessing](#5)\n",
    "    \n",
    "    * [5.1 Conversion to Lowercase](#5.1)\n",
    "    * [5.2 Removing Urls](#5.2)\n",
    "    * [5.3 Removing HTML Tags](#5.3)\n",
    "    * [5.4 Removing Punctuation](#5.4)\n",
    "    * [5.5 Replacing Shortconvo/Chatwords](#5.5)\n",
    "    * [5.6 Spelling Correction](#5.6)\n",
    "    * [5.7 Removing Stopwords](#5.7)\n",
    "    * [5.8 Removing Emojis](#5.8)\n",
    "    * [5.9 Lemmatization](#5.9)\n",
    "    \n",
    "* [6. Vectorization](#6) \n",
    "    * [6.1 Word2Vec](#6.1)\n",
    "      \n",
    "* [7. Data Preprocessing](#7)\n",
    "    \n",
    "* [8. Model Building](#8)\n",
    "    \n",
    "* [9. Model Evaluation](#9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Dataset</p>   \n",
    "https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Importing Libraries</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Loading Data</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"SMSSpamCollection\", delimiter=\"\\t\",names=[\"label\",\"message\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Visualization</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Palette\n",
    "cols= [\"#F39C12\", \"#E598D8\"] \n",
    "#first of all let us evaluate the target and find out if our data is imbalanced or not\n",
    "plt.figure(figsize=(12,8))\n",
    "fg = sns.countplot(x= data[\"label\"], palette= cols)\n",
    "fg.set_title(\"Count Plot of Classes\", color=\"#58508d\")\n",
    "fg.set_xlabel(\"Classes\", color=\"#58508d\")\n",
    "fg.set_ylabel(\"Number of Data points\", color=\"#58508d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Text Preprocessing</p>   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.1\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">1. Conversion to Lowercase</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.2\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">2. Removing Urls</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.3\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">3. Removing HTML Tags</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.4\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">4. Removing Punctuations</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('', '', punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].apply(remove_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.5\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">5. Replacing Short-Convo/Chat-Words</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Short Convo / Chat Words\n",
    "chat_words = {\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"B4\": \"Before\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GR8\": \"Great!\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
    "    \"ILU\": \"ILU: I Love You\",\n",
    "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMAO\": \"Laugh My A.. Off\",\n",
    "    \"LOL\": \"Laughing Out Loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"PITA\": \"Pain In The A..\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"QPSA?\": \"Que Pasa?\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your sex and age\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TTFN\": \"Ta-Ta For Now!\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The F...\",\n",
    "    \"WTG\": \"Way To Go!\",\n",
    "    \"WUF\": \"Where Are You From?\",\n",
    "    \"W8\": \"Wait...\",\n",
    "    \"7K\": \"Sick:-D Laugher\",\n",
    "    \"TFW\": \"That feeling when\",\n",
    "    \"MFW\": \"My face when\",\n",
    "    \"MRW\": \"My reaction when\",\n",
    "    \"IFYP\": \"I feel your pain\",\n",
    "    \"TNTL\": \"Trying not to laugh\",\n",
    "    \"JK\": \"Just kidding\",\n",
    "    \"IDC\": \"I don't care\",\n",
    "    \"ILY\": \"I love you\",\n",
    "    \"IMU\": \"I miss you\",\n",
    "    \"ADIH\": \"Another day in hell\",\n",
    "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
    "    \"WYWH\": \"Wish you were here\",\n",
    "    \"TIME\": \"Tears in my eyes\",\n",
    "    \"BAE\": \"Before anyone else\",\n",
    "    \"FIMH\": \"Forever in my heart\",\n",
    "    \"BSAAW\": \"Big smile and a wink\",\n",
    "    \"BWL\": \"Bursting with laughter\",\n",
    "    \"BFF\": \"Best friends forever\",\n",
    "    \"CSL\": \"Can't stop laughing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for i in text.split():\n",
    "        if i.upper() in chat_words:\n",
    "            new_text.append(chat_words[i.upper()])\n",
    "        else:\n",
    "            new_text.append(i)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].apply(chat_conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.6\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">6. Spelling Correction</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correct_spell(text):\n",
    "    return str(TextBlob(text).correct())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].apply(correct_spell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.7\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">7. Removing Stopwords</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in stopword:\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.8\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">8. Removing Emojis</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['message'] = data['message'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5.9\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">9. Lemmatization</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "# just apply stemming i have already done text preprocessing\n",
    "for i in range(0, len(data)):\n",
    "    # Keep only alphabetic characters and split into words\n",
    "    review = re.sub('[^a-zA-Z]', ' ', data['message'][i])\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in stopword]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[i, j, k] for i, j, k in zip(list(map(len, corpus)), corpus, data['message']) if i < 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Tokenization</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for sent in corpus:\n",
    "    sent_token=sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "        words.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Vectorization</p>   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6.1\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Word2Vec</p>   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Word2Vec Model from scratch\n",
    "model=gensim.models.Word2Vec(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similar_by_word(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    #sent = [word for word in doc if word in model.wv.index_to_key]\n",
    "    #print(sent)\n",
    "    \n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key],axis=0)\n",
    "                #or [np.zeros(len(model.wv.index_to_key))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "X=[]\n",
    "for i in tqdm(range(len(words))):\n",
    "    X.append(avg_word2vec(words[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Data Preprocessing</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array(X,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[list(map(lambda x: len(x) > 0, corpus))]\n",
    "y = pd.get_dummies(y['label'])  # Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Assuming X is defined (e.g., a list of numpy arrays)\n",
    "for i in range(len(X)):\n",
    "    dfs.append(pd.DataFrame(X[i].reshape(1, -1)))\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Output']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Model Building</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=RandomForestClassifier()\n",
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "# <p style=\"background:linear-gradient(135deg, #A2C2E4, #6C5B7B, #F1C40F);font-family:newtimeroman;color:#F39C12;font-size:100%;text-align:center;border-radius:20px 60px;\">Model Evaluation</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
